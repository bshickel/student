{"cells":[{"cell_type":"markdown","metadata":{"id":"IXjvBUbWAHBC"},"source":["![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true)\n","***\n","# *Practicum AI:* MNIST\n","\n","This exercise adapted from Baig et al. (2020) <i>The Deep Learning Workshop</i> from <a href=\"https://www.packtpub.com/product/the-deep-learning-workshop/9781839219856\">Packt Publishers</a> (Exercise 3.02, page 123).\n","\n","Introduction to Convolution Â© Daniel Moser, UT Southwestern Medical Center.\n","\n","<div style=\"padding: 10px;margin-bottom: 20px;border: thin solid #65BB7B;border-left-width: 10px;background-color: #fff\"><strong>Note:</strong> This is a rather famous deep learning exercise as it was an early application of CNN's.  At the time, banks needed a quick and easy way to automatically read the handwritten digits on checks.  This simple CNN, developed by Yann LeCun and co-researchers in 1998, solved that problem.</div>"]},{"cell_type":"markdown","metadata":{"id":"dsOgOOADAHBD"},"source":["#### Video Resources\n","- [Andrew Ng Stride Video](https://mediasite.video.ufl.edu/Mediasite/Play/98cde43b4e634b1cab8bc556b77846131d)\n","\n","- [Andrew Ng Padding Video](https://mediasite.video.ufl.edu/Mediasite/Play/09c6ef5af6ed4ea79ad6837e0f5680c31d)\n","\n","- [Andrew Ng Pooling Video](https://mediasite.video.ufl.edu/Mediasite/Play/8fe4282e539644ce9863eceefe258b931d)"]},{"cell_type":"markdown","source":["# Brief Introduction to Convolution\n","Before, we saw a demonstration of using deep learning with **structured**, numerical data. However, one of the largest advantages of using deep learning is with **unstructured** data, such as images. One way to design a classifier for images would be to use each pixel as a separate input feature. However, what if we could instead feed different **spatial** features (e.g. **curvature, edges**) of each image into a network, and have the network learn which features are important for classifying an image? \n","\n","This possible through convolution! Convolution applies **kernels** (filters) that traverse through each image and generate **feature maps**.\n","\n","<img src='https://github.com/AviatorMoser/keras-mnist-tutorial/blob/master/convolution.gif?raw=1'>\n","\n","In the above example, the image is a 5 x 5 matrix and the kernel going over it is a 3 x 3 matrix. A dot product operation takes place between the image and the kernel and the convolved feature is generated. Each kernel in a CNN learns a different characteristic of an image.\n","\n","Kernels are often used in photoediting software to apply blurring, edge detection, sharpening, etc.\n","\n","Kernels in deep learning networks are used in similar ways, i.e. highlighting some feature. Combined with a system called **max pooling**, the non-highlighted elements are discarded from each feature map, leaving only the features of interest, reducing the number of learned parameters, and decreasing the computational cost (e.g. system memory).\n","\n","<img src='https://github.com/AviatorMoser/keras-mnist-tutorial/blob/master/max_pooling.png?raw=1'>\n","\n","We can also take convolutions of convolutions -- we can stack as many convolutions as we want, as long as there are enough pixels to fit a kernel."],"metadata":{"id":"5LOmoQfMBlT9"}},{"cell_type":"markdown","metadata":{"id":"2F9TN8ErAHBD"},"source":["#### 1. Import dataset\n","\n","Import the MNIST data set."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Rczq9tXYAHBD","executionInfo":{"status":"ok","timestamp":1654469402895,"user_tz":240,"elapsed":6209,"user":{"displayName":"Benjamin Shickel","userId":"07487924651552066401"}}},"outputs":[],"source":["import keras.datasets.mnist as mnist"]},{"cell_type":"markdown","metadata":{"id":"MZP4YlSWAHBE"},"source":["#### 2. Load MNIST data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ulP1qxrxAHBE"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"Hra2ZpOOAHBE"},"source":["#### 3. Examine label_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8NgXcd-IAHBE"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"iJT-KABFAHBE"},"source":["#### 4. Examine the training dataset\n","\n","Our training dataset has 60000  28 x 28 pixel images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KnOPdhFZAHBF"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","source":["View some samples in our training dataset to get a better feel for the data."],"metadata":{"id":"wQOWQEOpBQCy"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.gray()\n","\n","plt.imshow(features_train[0])"],"metadata":{"id":"KxwvJNQXBOoT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code it! (check out another example image)\n"],"metadata":{"id":"Md-PGi8SDx9I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code it!\n"],"metadata":{"id":"Rxi3ikodD0hq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JMWyaKZYAHBF"},"source":["#### 5. Examine the test dataset\n","\n","Our test dataset has 10000  28 x 28 pixel images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xoK6vy9_AHBF"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"Bf6cq4vUAHBF"},"source":["#### 6. Reshape the training and test datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bygkyi7UAHBF"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"ffGTAaBGAHBF"},"source":["#### 7. Standardize test and train features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYBA28bTAHBF"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"tsCDxIGaAHBF"},"source":["#### 8. Import additional libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCvJKEGEAHBF"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"]},{"cell_type":"markdown","metadata":{"id":"NdjECeNaAHBF"},"source":["#### 9. Set seeds to ensure reproducibility"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5tIeC-pXAHBG"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"ISxMcw6JAHBG"},"source":["#### 10. Instantiate a Keras sequential model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNCqZWBHAHBG"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"VD0QzFUWAHBG"},"source":["#### 11. Instantiate the 1st convolutional layer\n","\n","This layer contains 64 kernels of shape (3,3).  The activation function is *relu*, and the incoming data will be of shape (28, 28, 1)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gcNRU3SYAHBG"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"Tqz8OcOCAHBG"},"source":["#### 12. Instantiate the 2nd convolutional layer\n","\n","This layer contains 64 kernels of shape (3,3), using *relu* as the activation function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2OMqc__AHBG"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"fwxYhRAHAHBG"},"source":["#### 13. Instantiate a dense layer\n","\n","This layer contains 128 neurons, using *relu* as the activation function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3F1kIoLwAHBG"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"TwL7PI1xAHBG"},"source":["#### 14. Instantiate a dense layer\n","\n","This layer contains 10 neurons, using *relu* as the activation function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WtRzwtzsAHBG"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"bYUEsdDEAHBG"},"source":["#### 15. Add layers to the model\n","\n","Add the four layers that were just defined as well as two max pooling layers and a flatten layer, in the order indicated here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xfl-5cTmAHBH"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"fXDKOHlhAHBH"},"source":["#### 17. Compile the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1GG32hFaAHBH"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"tHSfdofzAHBH"},"source":["#### 18. Print a summary of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6BqLLyJAHBH"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"XFUg8jOrAHBH"},"source":["#### 19. Fit (train) the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gtYn5q0gAHBH"},"outputs":[],"source":["# Code it!"]},{"cell_type":"markdown","metadata":{"id":"x42GEDLsAHBH"},"source":["#### 20. Evaluate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f1fNBqf7AHBH"},"outputs":[],"source":["# Code it!"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"colab":{"name":"CNN-MNIST-Student.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}